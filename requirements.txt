einops>=0.8.0
numpy>=1.26.4
pillow>=11.3.0
diffusers>=0.32.0
safetensors>=0.4.5
tokenizers>=0.21.0
transformers[accelerate,tiktoken]>=4.56.0

# PyTorch with CUDA 12.8 support (install separately)
# torch==2.7.1
# torchvision==0.22.1  
# torchaudio==2.7.1
# Install with: pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1 --index-url https://download.pytorch.org/whl/cu128

# Performance optimizations (the model creator recommended this for up to 3x faster inference)
# flash-attn==2.8.3 --no-build-isolation
# flashinfer-python

